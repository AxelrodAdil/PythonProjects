{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n0             60         65.0     8450            7            5       2003   \n1             20         80.0     9600            6            8       1976   \n2             60         68.0    11250            7            5       2001   \n3             70         60.0     9550            7            5       1915   \n4             60         84.0    14260            8            5       2000   \n...          ...          ...      ...          ...          ...        ...   \n1455          60         62.0     7917            6            5       1999   \n1456          20         85.0    13175            6            6       1978   \n1457          70         66.0     9042            7            9       1941   \n1458          20         68.0     9717            5            6       1950   \n1459          20         75.0     9937            5            6       1965   \n\n      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  WoodDeckSF  \\\n0             2003       196.0         706           0  ...           0   \n1             1976         0.0         978           0  ...         298   \n2             2002       162.0         486           0  ...           0   \n3             1970         0.0         216           0  ...           0   \n4             2000       350.0         655           0  ...         192   \n...            ...         ...         ...         ...  ...         ...   \n1455          2000         0.0           0           0  ...           0   \n1456          1988       119.0         790         163  ...         349   \n1457          2006         0.0         275           0  ...           0   \n1458          1996         0.0          49        1029  ...         366   \n1459          1965         0.0         830         290  ...         736   \n\n      OpenPorchSF  EnclosedPorch  X3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n0              61              0           0            0         0        0   \n1               0              0           0            0         0        0   \n2              42              0           0            0         0        0   \n3              35            272           0            0         0        0   \n4              84              0           0            0         0        0   \n...           ...            ...         ...          ...       ...      ...   \n1455           40              0           0            0         0        0   \n1456            0              0           0            0         0        0   \n1457           60              0           0            0         0     2500   \n1458            0            112           0            0         0        0   \n1459           68              0           0            0         0        0   \n\n      MoSold  YrSold  HousePrice  \n0          2    2008           1  \n1          5    2007           1  \n2          9    2008           1  \n3          2    2006           0  \n4         12    2008           1  \n...      ...     ...         ...  \n1455       8    2007           0  \n1456       2    2010           1  \n1457       5    2010           1  \n1458       4    2010           0  \n1459       6    2008           0  \n\n[1460 rows x 37 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>X3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>HousePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>196.0</td>\n      <td>706</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>0.0</td>\n      <td>978</td>\n      <td>0</td>\n      <td>...</td>\n      <td>298</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>162.0</td>\n      <td>486</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>0.0</td>\n      <td>216</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>35</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>350.0</td>\n      <td>655</td>\n      <td>0</td>\n      <td>...</td>\n      <td>192</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>60</td>\n      <td>62.0</td>\n      <td>7917</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1999</td>\n      <td>2000</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>20</td>\n      <td>85.0</td>\n      <td>13175</td>\n      <td>6</td>\n      <td>6</td>\n      <td>1978</td>\n      <td>1988</td>\n      <td>119.0</td>\n      <td>790</td>\n      <td>163</td>\n      <td>...</td>\n      <td>349</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>70</td>\n      <td>66.0</td>\n      <td>9042</td>\n      <td>7</td>\n      <td>9</td>\n      <td>1941</td>\n      <td>2006</td>\n      <td>0.0</td>\n      <td>275</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2500</td>\n      <td>5</td>\n      <td>2010</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>20</td>\n      <td>68.0</td>\n      <td>9717</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1950</td>\n      <td>1996</td>\n      <td>0.0</td>\n      <td>49</td>\n      <td>1029</td>\n      <td>...</td>\n      <td>366</td>\n      <td>0</td>\n      <td>112</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>20</td>\n      <td>75.0</td>\n      <td>9937</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1965</td>\n      <td>1965</td>\n      <td>0.0</td>\n      <td>830</td>\n      <td>290</td>\n      <td>...</td>\n      <td>736</td>\n      <td>68</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1460 rows Ã— 37 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('House_Price.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "MSSubClass       0\nLotFrontage      0\nLotArea          0\nOverallQual      0\nOverallCond      0\nYearBuilt        0\nYearRemodAdd     0\nMasVnrArea       0\nBsmtFinSF1       0\nBsmtFinSF2       0\nBsmtUnfSF        0\nTotalBsmtSF      0\nX1stFlrSF        0\nX2ndFlrSF        0\nLowQualFinSF     0\nGrLivArea        0\nBsmtFullBath     0\nBsmtHalfBath     0\nFullBath         0\nHalfBath         0\nBedroomAbvGr     0\nKitchenAbvGr     0\nTotRmsAbvGrd     0\nFireplaces       0\nGarageYrBlt      0\nGarageCars       0\nGarageArea       0\nWoodDeckSF       0\nOpenPorchSF      0\nEnclosedPorch    0\nX3SsnPorch       0\nScreenPorch      0\nPoolArea         0\nMiscVal          0\nMoSold           0\nYrSold           0\nHousePrice       0\ndtype: int64"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n0             60         65.0     8450            7            5       2003   \n1             20         80.0     9600            6            8       1976   \n2             60         68.0    11250            7            5       2001   \n3             70         60.0     9550            7            5       1915   \n4             60         84.0    14260            8            5       2000   \n...          ...          ...      ...          ...          ...        ...   \n1455          60         62.0     7917            6            5       1999   \n1456          20         85.0    13175            6            6       1978   \n1457          70         66.0     9042            7            9       1941   \n1458          20         68.0     9717            5            6       1950   \n1459          20         75.0     9937            5            6       1965   \n\n      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageArea  \\\n0             2003       196.0         706           0  ...         548   \n1             1976         0.0         978           0  ...         460   \n2             2002       162.0         486           0  ...         608   \n3             1970         0.0         216           0  ...         642   \n4             2000       350.0         655           0  ...         836   \n...            ...         ...         ...         ...  ...         ...   \n1455          2000         0.0           0           0  ...         460   \n1456          1988       119.0         790         163  ...         500   \n1457          2006         0.0         275           0  ...         252   \n1458          1996         0.0          49        1029  ...         240   \n1459          1965         0.0         830         290  ...         276   \n\n      WoodDeckSF  OpenPorchSF  EnclosedPorch  X3SsnPorch  ScreenPorch  \\\n0              0           61              0           0            0   \n1            298            0              0           0            0   \n2              0           42              0           0            0   \n3              0           35            272           0            0   \n4            192           84              0           0            0   \n...          ...          ...            ...         ...          ...   \n1455           0           40              0           0            0   \n1456         349            0              0           0            0   \n1457           0           60              0           0            0   \n1458         366            0            112           0            0   \n1459         736           68              0           0            0   \n\n      PoolArea  MiscVal  MoSold  YrSold  \n0            0        0       2    2008  \n1            0        0       5    2007  \n2            0        0       9    2008  \n3            0        0       2    2006  \n4            0        0      12    2008  \n...        ...      ...     ...     ...  \n1455         0        0       8    2007  \n1456         0        0       2    2010  \n1457         0     2500       5    2010  \n1458         0        0       4    2010  \n1459         0        0       6    2008  \n\n[1460 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>GarageArea</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>X3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>196.0</td>\n      <td>706</td>\n      <td>0</td>\n      <td>...</td>\n      <td>548</td>\n      <td>0</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>0.0</td>\n      <td>978</td>\n      <td>0</td>\n      <td>...</td>\n      <td>460</td>\n      <td>298</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>162.0</td>\n      <td>486</td>\n      <td>0</td>\n      <td>...</td>\n      <td>608</td>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>0.0</td>\n      <td>216</td>\n      <td>0</td>\n      <td>...</td>\n      <td>642</td>\n      <td>0</td>\n      <td>35</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>350.0</td>\n      <td>655</td>\n      <td>0</td>\n      <td>...</td>\n      <td>836</td>\n      <td>192</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>60</td>\n      <td>62.0</td>\n      <td>7917</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1999</td>\n      <td>2000</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>460</td>\n      <td>0</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>20</td>\n      <td>85.0</td>\n      <td>13175</td>\n      <td>6</td>\n      <td>6</td>\n      <td>1978</td>\n      <td>1988</td>\n      <td>119.0</td>\n      <td>790</td>\n      <td>163</td>\n      <td>...</td>\n      <td>500</td>\n      <td>349</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>70</td>\n      <td>66.0</td>\n      <td>9042</td>\n      <td>7</td>\n      <td>9</td>\n      <td>1941</td>\n      <td>2006</td>\n      <td>0.0</td>\n      <td>275</td>\n      <td>0</td>\n      <td>...</td>\n      <td>252</td>\n      <td>0</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2500</td>\n      <td>5</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>20</td>\n      <td>68.0</td>\n      <td>9717</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1950</td>\n      <td>1996</td>\n      <td>0.0</td>\n      <td>49</td>\n      <td>1029</td>\n      <td>...</td>\n      <td>240</td>\n      <td>366</td>\n      <td>0</td>\n      <td>112</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>20</td>\n      <td>75.0</td>\n      <td>9937</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1965</td>\n      <td>1965</td>\n      <td>0.0</td>\n      <td>830</td>\n      <td>290</td>\n      <td>...</td>\n      <td>276</td>\n      <td>736</td>\n      <td>68</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n    </tr>\n  </tbody>\n</table>\n<p>1460 rows Ã— 36 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop([\"HousePrice\"], axis = 1)\n",
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0       1\n1       1\n2       1\n3       0\n4       1\n       ..\n1455    0\n1456    1\n1457    1\n1458    0\n1459    0\nName: HousePrice, Length: 1460, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df[\"HousePrice\"]\n",
    "Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n64            60    75.850000     9375            7            5       1997   \n682          120    63.354762     2887            6            5       1996   \n960           20    50.000000     7207            5            7       1958   \n1384          50    60.000000     9060            6            5       1939   \n1100          30    60.000000     8400            2            5       1920   \n...          ...          ...      ...          ...          ...        ...   \n763           60    82.000000     9430            8            5       1999   \n835           20    60.000000     9600            4            7       1950   \n1216          90    68.000000     8930            6            5       1978   \n559          120    46.160000     3196            7            5       2003   \n684           60    58.000000    16770            7            5       1998   \n\n      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageArea  \\\n64            1998       573.0         739           0  ...         645   \n682           1997         0.0        1003           0  ...         431   \n960           2008         0.0         696           0  ...           0   \n1384          1950         0.0         204           0  ...         280   \n1100          1950         0.0         290           0  ...         246   \n...            ...         ...         ...         ...  ...         ...   \n763           1999       673.0        1163           0  ...         856   \n835           1995         0.0         442           0  ...         436   \n1216          1978         0.0           0           0  ...         539   \n559           2004        18.0           0           0  ...         420   \n684           1998        30.0           0           0  ...         486   \n\n      WoodDeckSF  OpenPorchSF  EnclosedPorch  X3SsnPorch  ScreenPorch  \\\n64           576           36              0           0            0   \n682          307            0              0           0            0   \n960          117            0              0           0            0   \n1384           0            0              0           0            0   \n1100           0            0              0           0            0   \n...          ...          ...            ...         ...          ...   \n763            0          128              0           0          180   \n835          290            0              0           0            0   \n1216           0            0              0           0            0   \n559          143           20              0           0            0   \n684            0           81              0           0            0   \n\n      PoolArea  MiscVal  MoSold  YrSold  \n64           0        0       2    2009  \n682          0        0      11    2008  \n960          0        0       2    2010  \n1384         0        0      10    2009  \n1100         0        0       1    2009  \n...        ...      ...     ...     ...  \n763          0        0       7    2009  \n835          0        0       2    2010  \n1216         0        0       4    2010  \n559          0        0      10    2006  \n684          0        0       6    2010  \n\n[1022 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>GarageArea</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>X3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>64</th>\n      <td>60</td>\n      <td>75.850000</td>\n      <td>9375</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1997</td>\n      <td>1998</td>\n      <td>573.0</td>\n      <td>739</td>\n      <td>0</td>\n      <td>...</td>\n      <td>645</td>\n      <td>576</td>\n      <td>36</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>682</th>\n      <td>120</td>\n      <td>63.354762</td>\n      <td>2887</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1996</td>\n      <td>1997</td>\n      <td>0.0</td>\n      <td>1003</td>\n      <td>0</td>\n      <td>...</td>\n      <td>431</td>\n      <td>307</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>960</th>\n      <td>20</td>\n      <td>50.000000</td>\n      <td>7207</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1958</td>\n      <td>2008</td>\n      <td>0.0</td>\n      <td>696</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>117</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1384</th>\n      <td>50</td>\n      <td>60.000000</td>\n      <td>9060</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1939</td>\n      <td>1950</td>\n      <td>0.0</td>\n      <td>204</td>\n      <td>0</td>\n      <td>...</td>\n      <td>280</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>1100</th>\n      <td>30</td>\n      <td>60.000000</td>\n      <td>8400</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1920</td>\n      <td>1950</td>\n      <td>0.0</td>\n      <td>290</td>\n      <td>0</td>\n      <td>...</td>\n      <td>246</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>60</td>\n      <td>82.000000</td>\n      <td>9430</td>\n      <td>8</td>\n      <td>5</td>\n      <td>1999</td>\n      <td>1999</td>\n      <td>673.0</td>\n      <td>1163</td>\n      <td>0</td>\n      <td>...</td>\n      <td>856</td>\n      <td>0</td>\n      <td>128</td>\n      <td>0</td>\n      <td>0</td>\n      <td>180</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>835</th>\n      <td>20</td>\n      <td>60.000000</td>\n      <td>9600</td>\n      <td>4</td>\n      <td>7</td>\n      <td>1950</td>\n      <td>1995</td>\n      <td>0.0</td>\n      <td>442</td>\n      <td>0</td>\n      <td>...</td>\n      <td>436</td>\n      <td>290</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1216</th>\n      <td>90</td>\n      <td>68.000000</td>\n      <td>8930</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1978</td>\n      <td>1978</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>539</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>559</th>\n      <td>120</td>\n      <td>46.160000</td>\n      <td>3196</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2004</td>\n      <td>18.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>420</td>\n      <td>143</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>684</th>\n      <td>60</td>\n      <td>58.000000</td>\n      <td>16770</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1998</td>\n      <td>1998</td>\n      <td>30.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>486</td>\n      <td>0</td>\n      <td>81</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2010</td>\n    </tr>\n  </tbody>\n</table>\n<p>1022 rows Ã— 36 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_Train,X_Test,Y_Train,Y_Test = train_test_split(X,Y,test_size=0.3,random_state=0)\n",
    "# x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)\n",
    "X_Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(criterion='entropy', n_estimators=5, random_state=0)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=5, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=5, random_state=0)</pre></div></div></div></div></div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "X_Train = sc_X.fit_transform(X_Train)\n",
    "X_Test = sc_X.transform(X_Test)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 5, criterion = 'entropy', random_state = 0)\n",
    "rfc.fit(X_Train,Y_Train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "? RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "? RandomForestRegressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "Y_Pred = rfc.predict(X_Test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[255,   9],\n       [ 37, 137]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_Test, Y_Pred)\n",
    "cm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8949771689497716\n",
      "0.9383561643835616\n",
      "0.7873563218390804\n",
      "0.85625\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.accuracy_score(Y_Test, Y_Pred))\n",
    "print(metrics.precision_score(Y_Test, Y_Pred))\n",
    "print(metrics.recall_score(Y_Test, Y_Pred))\n",
    "print(metrics.f1_score(Y_Test, Y_Pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestRegressor(n_estimators=5, random_state=0)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=5, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=5, random_state=0)</pre></div></div></div></div></div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestRegressor(n_estimators = 5, random_state = 0)\n",
    "rfc.fit(X_Train,Y_Train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.6, 0.2, 0. , 1. , 0. , 0. , 0.8, 0. , 1. , 0. , 0.6, 0.2, 1. ,\n       0. , 0. , 0. , 1. , 0. , 0. , 0.4, 0. , 0. , 0. , 0. , 0.4, 1. ,\n       0.2, 0. , 1. , 0. , 0. , 0.2, 0. , 1. , 0.6, 0. , 1. , 0. , 1. ,\n       1. , 0.8, 0. , 0.8, 1. , 1. , 0. , 0. , 0. , 0.4, 0. , 1. , 0. ,\n       0. , 0. , 1. , 0. , 0. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0.4,\n       0.6, 0. , 1. , 0. , 1. , 0. , 0. , 0. , 0.8, 0. , 1. , 0. , 0. ,\n       1. , 0. , 0. , 0. , 0. , 0. , 0.8, 1. , 0. , 0.8, 0. , 0. , 0.8,\n       0.8, 0.4, 1. , 0.4, 0. , 1. , 0.4, 0. , 0.4, 0.8, 0.4, 0. , 0. ,\n       0. , 0.8, 0. , 0. , 0.2, 0. , 0. , 0. , 0.4, 0. , 0.2, 0.2, 0.6,\n       0. , 0.6, 1. , 0.4, 0.2, 0. , 1. , 0.8, 0.8, 1. , 0.6, 1. , 0. ,\n       0.8, 0.6, 0.2, 0. , 0. , 1. , 0. , 0.4, 0. , 0.4, 0. , 0. , 0.8,\n       0. , 0. , 0.2, 1. , 0. , 1. , 1. , 0. , 1. , 1. , 0.6, 0. , 0.8,\n       0. , 0.6, 0.2, 0. , 0. , 0. , 0.4, 0. , 1. , 0. , 0. , 1. , 1. ,\n       0.2, 0. , 0. , 0.4, 0. , 0. , 0. , 0. , 0.8, 0. , 0. , 1. , 1. ,\n       0. , 1. , 0. , 0.4, 0. , 1. , 0.6, 0. , 0.2, 0. , 1. , 0. , 0. ,\n       0. , 0. , 0. , 0.4, 0. , 0. , 0.4, 0. , 0. , 0.2, 0.2, 0. , 1. ,\n       1. , 0. , 0.2, 1. , 0. , 0. , 1. , 0.6, 0.4, 1. , 1. , 0. , 0.6,\n       0.2, 0.4, 0. , 0.4, 1. , 1. , 1. , 0. , 0.4, 0. , 0.2, 0. , 0. ,\n       1. , 0. , 0. , 0. , 0. , 0.4, 0. , 0.6, 1. , 1. , 0. , 0.6, 0.8,\n       0.4, 0. , 0.8, 0. , 1. , 0. , 1. , 1. , 1. , 0. , 0.6, 1. , 1. ,\n       0.2, 0.2, 0. , 0. , 1. , 1. , 1. , 0. , 0.8, 1. , 0. , 0.8, 0. ,\n       0.4, 0.2, 1. , 1. , 0.8, 1. , 0. , 0. , 1. , 0. , 0. , 0.6, 0.2,\n       0. , 1. , 1. , 0.4, 0. , 0. , 0.8, 0. , 0. , 1. , 1. , 0.8, 0. ,\n       0. , 0. , 0. , 0.2, 0. , 0.4, 0. , 0. , 0. , 0. , 0.2, 0. , 0.6,\n       0.4, 0. , 0. , 0. , 1. , 0. , 0. , 0. , 0. , 1. , 0. , 1. , 0. ,\n       1. , 0. , 1. , 0.6, 0.2, 0. , 0.8, 0.2, 0.6, 0.2, 0. , 0. , 0.2,\n       0.2, 0. , 1. , 0.2, 0.2, 1. , 0. , 0. , 0. , 0. , 0. , 0. , 1. ,\n       1. , 0. , 0. , 0.2, 1. , 1. , 0. , 1. , 1. , 1. , 0.6, 1. , 1. ,\n       0. , 0. , 0. , 0. , 0.4, 0. , 0.6, 0. , 0. , 0. , 0. , 0.2, 0.6,\n       1. , 0. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. , 1. ,\n       0. , 0. , 1. , 0. , 0. , 0. , 0.2, 0.2, 0. , 0.6, 1. , 1. , 0.2,\n       0. , 0. , 1. , 0. , 1. , 1. , 1. , 0. , 0. , 1. , 0. , 0. , 0. ,\n       1. , 0. , 1. , 0. , 1. , 1. , 0. , 0. , 0. , 0. , 0.4, 0. , 0.2,\n       0. , 0. , 1. , 0. , 0.8, 0. , 1. , 1. , 1. ])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Pred = rfc.predict(X_Test)\n",
    "Y_Pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13287671232876713\n",
      "0.08063926940639271\n",
      "0.6632236154649946\n"
     ]
    }
   ],
   "source": [
    "print(metrics.mean_absolute_error(Y_Test, Y_Pred))\n",
    "print(metrics.mean_squared_error(Y_Test, Y_Pred))\n",
    "\n",
    "# 50-den assa jaksy!!!\n",
    "print(metrics.r2_score(Y_Test, Y_Pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "GradientBoostingClassifier(n_estimators=5, random_state=0)",
      "text/html": "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(n_estimators=5, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(n_estimators=5, random_state=0)</pre></div></div></div></div></div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=5, random_state=0)\n",
    "gbc.fit(X_Train, Y_Train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n       1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Pred = gbc.predict(X_Test)\n",
    "Y_Pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[250,  14],\n       [ 51, 123]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_Test, Y_Pred)\n",
    "cm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8515981735159818\n",
      "0.8978102189781022\n",
      "0.7068965517241379\n",
      "0.7909967845659164\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Y_Test, Y_Pred))\n",
    "print(metrics.precision_score(Y_Test, Y_Pred))\n",
    "print(metrics.recall_score(Y_Test, Y_Pred))\n",
    "print(metrics.f1_score(Y_Test, Y_Pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "GradientBoostingRegressor(n_estimators=5, random_state=0)",
      "text/html": "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(n_estimators=5, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(n_estimators=5, random_state=0)</pre></div></div></div></div></div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingRegressor(n_estimators=5, random_state=0)\n",
    "gbc.fit(X_Train, Y_Train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.4274498 , 0.29260572, 0.23126599, 0.56815801, 0.23126599,\n       0.23126599, 0.60644543, 0.23126599, 0.60644543, 0.25340702,\n       0.58939822, 0.44455023, 0.60644543, 0.23126599, 0.23126599,\n       0.23126599, 0.55777826, 0.23126599, 0.23126599, 0.49980415,\n       0.23126599, 0.23126599, 0.23126599, 0.23126599, 0.31687852,\n       0.55023181, 0.44012144, 0.23126599, 0.60644543, 0.23126599,\n       0.36563145, 0.40909055, 0.23126599, 0.60644543, 0.60644543,\n       0.25340702, 0.60644543, 0.23126599, 0.60644543, 0.60644543,\n       0.38238233, 0.23126599, 0.5111993 , 0.60644543, 0.60644543,\n       0.36563145, 0.23126599, 0.23126599, 0.3715245 , 0.23126599,\n       0.60644543, 0.23126599, 0.23126599, 0.23126599, 0.60644543,\n       0.23126599, 0.23126599, 0.60644543, 0.23126599, 0.23126599,\n       0.23126599, 0.23126599, 0.23126599, 0.23126599, 0.40942839,\n       0.3402831 , 0.23126599, 0.60644543, 0.23126599, 0.55023181,\n       0.36992414, 0.23126599, 0.23126599, 0.5771146 , 0.23126599,\n       0.60644543, 0.23126599, 0.23126599, 0.60644543, 0.23126599,\n       0.23126599, 0.23126599, 0.23126599, 0.23126599, 0.41307539,\n       0.49891568, 0.23126599, 0.58939822, 0.23126599, 0.23126599,\n       0.47802532, 0.42900375, 0.29986293, 0.60644543, 0.49891568,\n       0.23126599, 0.60644543, 0.29260572, 0.23126599, 0.29260572,\n       0.60644543, 0.30962064, 0.23126599, 0.23126599, 0.23126599,\n       0.58939822, 0.23126599, 0.23126599, 0.23126599, 0.23126599,\n       0.23126599, 0.23126599, 0.36405381, 0.23126599, 0.30962064,\n       0.23126599, 0.60644543, 0.23126599, 0.36405381, 0.60644543,\n       0.46077164, 0.28028981, 0.23126599, 0.56815801, 0.58939822,\n       0.60644543, 0.60644543, 0.49891568, 0.49891568, 0.23126599,\n       0.5771146 , 0.49891568, 0.3957973 , 0.25922424, 0.23126599,\n       0.60644543, 0.23126599, 0.5771146 , 0.23126599, 0.44012144,\n       0.23126599, 0.23126599, 0.38954592, 0.23126599, 0.23126599,\n       0.29986293, 0.60644543, 0.23126599, 0.60644543, 0.60644543,\n       0.23126599, 0.60644543, 0.60644543, 0.40380397, 0.25340702,\n       0.56815801, 0.23126599, 0.51194439, 0.23126599, 0.36992414,\n       0.23126599, 0.23126599, 0.30962064, 0.23126599, 0.60644543,\n       0.23126599, 0.23126599, 0.60644543, 0.5771146 , 0.3715245 ,\n       0.23126599, 0.3715245 , 0.23126599, 0.23126599, 0.23126599,\n       0.23126599, 0.23126599, 0.45097927, 0.23126599, 0.23126599,\n       0.60644543, 0.55777826, 0.23126599, 0.60644543, 0.23126599,\n       0.29260572, 0.23126599, 0.49891568, 0.5771146 , 0.23126599,\n       0.23126599, 0.23126599, 0.60644543, 0.23126599, 0.23126599,\n       0.23126599, 0.23126599, 0.23126599, 0.31218108, 0.23126599,\n       0.23126599, 0.5111993 , 0.23126599, 0.23126599, 0.36590009,\n       0.40195769, 0.23126599, 0.60644543, 0.60644543, 0.23126599,\n       0.23126599, 0.60644543, 0.23126599, 0.23126599, 0.60644543,\n       0.36405381, 0.53882719, 0.60644543, 0.60644543, 0.23126599,\n       0.60644543, 0.23126599, 0.29260572, 0.23126599, 0.58939822,\n       0.60644543, 0.60644543, 0.38954592, 0.23126599, 0.55111081,\n       0.23126599, 0.28028981, 0.23126599, 0.23126599, 0.55023181,\n       0.23126599, 0.31687852, 0.23126599, 0.23126599, 0.3402831 ,\n       0.23126599, 0.44012144, 0.55023181, 0.60644543, 0.23126599,\n       0.5111993 , 0.5771146 , 0.30962064, 0.23126599, 0.5771146 ,\n       0.23126599, 0.60644543, 0.23126599, 0.60644543, 0.49891568,\n       0.60644543, 0.23126599, 0.60644543, 0.60644543, 0.60644543,\n       0.55023181, 0.23126599, 0.34447845, 0.23126599, 0.60644543,\n       0.58939822, 0.60644543, 0.23126599, 0.53897057, 0.60644543,\n       0.23126599, 0.53897057, 0.23126599, 0.3715245 , 0.31687852,\n       0.60644543, 0.55777826, 0.49980415, 0.55023181, 0.23126599,\n       0.23126599, 0.60644543, 0.23126599, 0.23126599, 0.49891568,\n       0.4274498 , 0.23126599, 0.58939822, 0.60644543, 0.31687852,\n       0.23126599, 0.23126599, 0.60644543, 0.23126599, 0.23126599,\n       0.60644543, 0.60644543, 0.5111993 , 0.23126599, 0.28028981,\n       0.23126599, 0.23126599, 0.25340702, 0.23126599, 0.31687852,\n       0.23126599, 0.23126599, 0.23126599, 0.25340702, 0.49891568,\n       0.23126599, 0.23126599, 0.55111081, 0.23126599, 0.23126599,\n       0.23126599, 0.60644543, 0.23126599, 0.58939822, 0.36405381,\n       0.23126599, 0.60644543, 0.23126599, 0.56815801, 0.36590009,\n       0.60644543, 0.23126599, 0.60644543, 0.3305096 , 0.23126599,\n       0.23126599, 0.54073106, 0.29260572, 0.5111993 , 0.34939592,\n       0.23126599, 0.23126599, 0.28028981, 0.25340702, 0.23126599,\n       0.60644543, 0.23126599, 0.30962064, 0.55023181, 0.23126599,\n       0.23126599, 0.23126599, 0.23126599, 0.23126599, 0.23126599,\n       0.60644543, 0.60644543, 0.23126599, 0.23126599, 0.23126599,\n       0.60644543, 0.60644543, 0.35008497, 0.60644543, 0.38238233,\n       0.60644543, 0.42339723, 0.60644543, 0.60644543, 0.23126599,\n       0.31687852, 0.36992414, 0.23126599, 0.49199417, 0.23126599,\n       0.60644543, 0.23126599, 0.31687852, 0.23126599, 0.23126599,\n       0.23126599, 0.3402831 , 0.60644543, 0.23126599, 0.60644543,\n       0.23126599, 0.23126599, 0.23126599, 0.23126599, 0.23126599,\n       0.23126599, 0.23126599, 0.30962064, 0.60644543, 0.60644543,\n       0.23126599, 0.23126599, 0.38238233, 0.23126599, 0.23126599,\n       0.23126599, 0.49891568, 0.23126599, 0.23126599, 0.40942839,\n       0.60644543, 0.60644543, 0.29260572, 0.23126599, 0.23126599,\n       0.60644543, 0.23126599, 0.60644543, 0.60644543, 0.60644543,\n       0.3715245 , 0.23126599, 0.58939822, 0.31687852, 0.29260572,\n       0.23126599, 0.58939822, 0.23126599, 0.60644543, 0.23126599,\n       0.60644543, 0.60644543, 0.23126599, 0.23126599, 0.23126599,\n       0.23126599, 0.56815801, 0.23126599, 0.54073106, 0.23126599,\n       0.23126599, 0.60644543, 0.23126599, 0.58939822, 0.32056398,\n       0.60644543, 0.60644543, 0.60644543])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Pred = gbc.predict(X_Test)\n",
    "Y_Pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3516443774291465\n",
      "0.14329941991939324\n",
      "0.401534005681468\n"
     ]
    }
   ],
   "source": [
    "print(metrics.mean_absolute_error(Y_Test, Y_Pred))\n",
    "print(metrics.mean_squared_error(Y_Test, Y_Pred))\n",
    "\n",
    "# 50-den assa jaksy!!!\n",
    "print(metrics.r2_score(Y_Test, Y_Pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n             early_stopping_rounds=None, enable_categorical=False,\n             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n             importance_type=None, interaction_constraints='',\n             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n             reg_lambda=1, ...)",
      "text/html": "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n             early_stopping_rounds=None, enable_categorical=False,\n             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n             importance_type=None, interaction_constraints=&#x27;&#x27;,\n             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n             reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n             early_stopping_rounds=None, enable_categorical=False,\n             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n             importance_type=None, interaction_constraints=&#x27;&#x27;,\n             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n             reg_lambda=1, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(X_Train, Y_Train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 5.94514906e-01,  3.44384573e-02, -1.87716610e-03,  9.08876061e-01,\n       -1.36833442e-02, -1.32965213e-02,  9.94819641e-01,  1.93554536e-03,\n        1.06453300e+00, -7.70483166e-03,  9.05660331e-01,  4.35491651e-01,\n        9.85958934e-01, -1.42389489e-02, -2.20418274e-02, -3.31973145e-03,\n        7.70582139e-01,  1.62262991e-02,  7.62482956e-02,  7.31162429e-01,\n        4.06320021e-02, -3.94188159e-04, -8.80533829e-03,  3.90002914e-02,\n        2.26739973e-01,  8.20267022e-01,  1.16065577e-01,  5.97307365e-03,\n        9.99584734e-01, -2.24556029e-03, -3.82394344e-02,  3.43814582e-01,\n        7.08662905e-03,  1.00464785e+00,  1.00313449e+00,  3.21902066e-01,\n        9.82545495e-01,  2.87240976e-03,  1.00642157e+00,  1.03928375e+00,\n        7.22566903e-01, -4.20527952e-03,  8.60123456e-01,  1.00417364e+00,\n        1.01922786e+00, -1.24829717e-01, -4.95570339e-03, -2.61370861e-03,\n        1.89817443e-01, -3.46103194e-03,  1.01310873e+00, -1.41172099e-03,\n        1.04296058e-02, -1.42593356e-02,  9.15542185e-01, -1.34023353e-02,\n        1.62394457e-02,  9.65629280e-01,  8.49043718e-04,  3.69803212e-03,\n       -1.63672622e-02, -1.79289572e-03, -5.97620383e-03,  7.58160139e-03,\n        7.00808525e-01,  1.23977013e-01, -8.61220155e-03,  9.54067588e-01,\n       -5.04932441e-02,  8.13622653e-01,  2.95864075e-01,  5.74641628e-03,\n        3.14529217e-03,  9.20684218e-01,  1.18861452e-03,  9.62199926e-01,\n       -3.32708918e-02, -2.35550548e-03,  1.01113105e+00, -4.32696007e-02,\n       -4.03713249e-03, -2.83551286e-03,  3.02596018e-02,  5.94567833e-03,\n        7.89061189e-01,  9.03211951e-01, -2.99953739e-04,  9.53581512e-01,\n        4.21522886e-01,  2.62734178e-03,  1.04399538e+00,  5.87804794e-01,\n        2.80027658e-01,  1.03284717e+00,  5.04283011e-02, -2.16657086e-03,\n        9.93844569e-01,  2.30593190e-01, -8.93612392e-04,  6.87776133e-02,\n        9.75952744e-01,  9.18762907e-02,  3.22012268e-02,  1.30298693e-04,\n       -7.46607035e-03,  1.01920807e+00,  8.30278397e-02, -4.12187213e-03,\n        2.26145566e-01, -2.95418897e-03, -2.43609399e-03,  2.86566163e-03,\n        7.99513340e-01,  1.38092106e-02, -2.63283737e-02,  2.32280314e-01,\n        9.57373142e-01,  9.11957212e-03,  5.66266537e-01,  9.61256266e-01,\n        8.90537560e-01,  3.10120899e-02,  7.01724086e-03,  8.65574300e-01,\n        9.77936864e-01,  9.61575329e-01,  9.99602675e-01,  3.68151039e-01,\n        1.02979267e+00,  6.33154809e-02,  7.10720062e-01,  2.88009703e-01,\n        1.80133641e-01,  2.44068310e-01, -8.08946136e-03,  1.07005703e+00,\n       -7.14380853e-03,  7.40054011e-01, -4.70706448e-03,  4.49512303e-01,\n       -5.27643505e-03,  6.29595667e-03,  5.05822003e-01,  3.76631171e-02,\n       -6.85554370e-03,  4.07216907e-01,  1.05390251e+00,  1.34323109e-02,\n        9.51943636e-01,  9.60701108e-01, -4.41813581e-02,  1.00619709e+00,\n        5.52670777e-01,  3.34137261e-01,  9.80092660e-02,  1.03356314e+00,\n       -3.07456274e-02,  2.70000547e-01,  7.42608160e-02, -7.55401608e-03,\n       -3.75031173e-04, -1.09530671e-03,  2.37637281e-01, -7.90796429e-02,\n        1.00557065e+00, -2.87900176e-02,  3.58658545e-02,  9.89795685e-01,\n        9.60162044e-01,  2.23180547e-01,  3.70813943e-02,  8.73042047e-02,\n        1.58044860e-01, -1.11693218e-02,  8.29494372e-02,  3.66051793e-02,\n       -1.08735985e-04,  9.33246911e-01,  1.62313767e-02,  1.56003349e-02,\n        1.14927173e+00,  7.21735239e-01, -2.75589083e-03,  1.00410092e+00,\n       -6.16979506e-03,  3.41723636e-02,  1.70047246e-02,  1.01250958e+00,\n        6.55958593e-01,  2.30830949e-04,  1.36574823e-02,  2.31643617e-01,\n        9.48670387e-01, -2.48241406e-02, -1.24191381e-02,  7.57674716e-05,\n        6.16155099e-04,  6.07597642e-03,  2.87557960e-01, -3.39313620e-03,\n        9.47739929e-04,  5.57940751e-02,  1.16278194e-02,  2.49373703e-03,\n        5.48175871e-01,  4.77314472e-01, -9.22711100e-03,  9.24670637e-01,\n        9.88873959e-01,  4.10030922e-03,  3.36932689e-02,  9.76751626e-01,\n       -2.94874958e-03,  1.32301659e-03,  1.13575625e+00,  9.10168648e-01,\n        2.14883357e-01,  1.04455781e+00,  1.02313948e+00, -3.40984156e-03,\n        6.62811697e-01,  3.60634066e-02,  2.52322495e-01, -4.31620097e-03,\n        3.61611575e-01,  9.96143639e-01,  1.01796162e+00,  1.04448402e+00,\n       -1.44832665e-02,  2.32247710e-01, -6.84490521e-03,  5.83560839e-02,\n       -6.46473665e-04,  1.01392390e-02,  1.02737474e+00, -1.84445865e-02,\n        1.84008814e-02,  1.65361911e-03, -7.92866689e-04,  5.03812850e-01,\n        9.82236583e-04,  4.98978406e-01,  9.15214896e-01,  9.90441203e-01,\n        5.33587970e-02,  3.08503825e-02,  3.88927788e-01,  2.21034274e-01,\n       -1.72548331e-02,  9.99430299e-01,  6.91853091e-02,  9.89163578e-01,\n       -6.15183683e-03,  1.03615355e+00,  1.18983078e+00,  8.49714100e-01,\n        9.97261982e-03,  1.61449179e-01,  1.01369345e+00,  1.04359162e+00,\n        2.43827641e-01, -5.81055507e-03, -1.15420975e-01, -2.52470318e-02,\n        1.01168191e+00,  1.00898004e+00,  1.07298851e+00,  2.38136621e-03,\n        9.09476876e-01,  1.01994038e+00,  4.99527995e-03,  1.00140190e+00,\n       -6.10431563e-03,  2.00808838e-01, -3.11652888e-02,  9.90766585e-01,\n        9.54548657e-01,  9.64083970e-01,  8.47022653e-01,  1.65696628e-02,\n        1.74535078e-03,  9.92032111e-01,  2.69882500e-01, -2.74838340e-02,\n        2.40599111e-01,  2.03667223e-01, -4.29455377e-03,  1.04350233e+00,\n        1.02262485e+00,  3.16283703e-01,  4.99948906e-03,  5.27402386e-03,\n        9.94336426e-01, -7.98925757e-03,  8.77596438e-03,  1.01985681e+00,\n        9.75183308e-01,  8.46735656e-01, -3.32398750e-02,  4.58766818e-02,\n        1.41510111e-03, -1.18626822e-02,  1.79922178e-01,  1.32581115e-01,\n        5.89754842e-02,  1.10884421e-01, -1.29870959e-02, -6.79753534e-03,\n        1.50547862e-01,  7.95792416e-03, -1.44047115e-03,  2.07184199e-02,\n        1.42818898e-01,  1.57296122e-03,  5.75459888e-03, -2.69603985e-03,\n        1.02430987e+00,  3.09229153e-03,  5.37024617e-01,  6.51572496e-02,\n       -1.58709940e-02,  9.81817663e-01, -3.83247412e-03,  9.89269376e-01,\n        3.41892540e-01,  9.92222965e-01, -2.97139138e-02,  1.00111914e+00,\n        4.81951952e-01,  1.52046261e-02, -5.23542927e-04,  9.10409868e-01,\n        6.21182993e-02,  6.84797585e-01,  3.23718160e-01,  4.42924462e-02,\n        1.21276416e-02,  6.67419136e-02,  3.42656784e-02,  1.24543225e-02,\n        9.87456620e-01, -1.89381745e-02,  1.70761362e-01,  8.60444009e-01,\n        1.52948638e-02, -1.51726054e-02,  1.03714220e-01, -1.57912925e-03,\n        6.93268201e-04, -1.11750960e-02,  9.88392115e-01,  1.00850487e+00,\n       -2.59096245e-03,  1.37211401e-02,  6.31487519e-02,  1.01327574e+00,\n        1.01188385e+00,  2.78045326e-01,  1.01759517e+00,  1.16707945e+00,\n        1.03072274e+00,  7.90606022e-01,  9.82721627e-01,  9.52132225e-01,\n       -2.25206930e-02,  7.56348893e-02, -7.38462880e-02, -1.59806572e-03,\n        3.10907781e-01,  3.41503769e-02,  9.55706537e-01,  5.40264370e-03,\n       -8.30148384e-02,  5.60324872e-04,  7.86769949e-03,  5.04092239e-02,\n        6.02948904e-01,  9.89737511e-01, -5.54491114e-03,  1.04126024e+00,\n        1.43213719e-02, -1.83350183e-02, -6.97592320e-03, -1.45115536e-02,\n       -5.36456425e-03, -4.13204136e-04,  1.39518917e-01,  2.35736668e-01,\n        1.01622355e+00,  1.00526595e+00, -8.15274939e-03, -1.27556466e-03,\n        4.86841381e-01,  1.94762349e-02, -2.12882645e-02,  1.06725022e-02,\n        5.64314604e-01, -1.29791703e-02, -3.65927406e-02,  1.01902986e+00,\n        9.86629009e-01,  9.93191242e-01,  1.15059920e-01, -5.51310694e-03,\n        1.25632146e-02,  1.01007652e+00, -3.64178456e-02,  1.02205741e+00,\n        1.00712705e+00,  9.76780176e-01,  1.95110396e-01,  1.05635813e-02,\n        9.48228061e-01, -5.14258891e-02, -3.60019617e-02, -1.02876723e-02,\n        8.62440646e-01,  1.42887346e-02,  9.72663760e-01,  8.07066485e-02,\n        9.97553170e-01,  1.00640178e+00, -1.91428978e-03,  1.40550523e-03,\n       -1.10799912e-02,  1.10908831e-02,  5.82317889e-01,  1.20906299e-02,\n        4.83341336e-01, -5.62239578e-03, -3.17009799e-02,  9.95174944e-01,\n        3.51966023e-02,  9.81961608e-01,  2.14748387e-03,  1.04946101e+00,\n        9.75114584e-01,  1.00323784e+00], dtype=float32)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Pred = xgb.predict(X_Test)\n",
    "Y_Pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13954220189256183\n",
      "0.08201144068857441\n",
      "0.6574929722340023\n"
     ]
    }
   ],
   "source": [
    "print(metrics.mean_absolute_error(Y_Test, Y_Pred))\n",
    "print(metrics.mean_squared_error(Y_Test, Y_Pred))\n",
    "\n",
    "# 50-den assa jaksy!!!\n",
    "print(metrics.r2_score(Y_Test, Y_Pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n              importance_type=None, interaction_constraints='',\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints='()', n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n              reg_alpha=0, reg_lambda=1, ...)",
      "text/html": "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_Train, Y_Train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n       0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n       1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n       1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n       0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n       1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Pred = xgb.predict(X_Test)\n",
    "Y_Pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.908675799086758\n",
      "0.9135802469135802\n",
      "0.8505747126436781\n",
      "0.8809523809523809\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Y_Test, Y_Pred))\n",
    "print(metrics.precision_score(Y_Test, Y_Pred))\n",
    "print(metrics.recall_score(Y_Test, Y_Pred))\n",
    "print(metrics.f1_score(Y_Test, Y_Pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
