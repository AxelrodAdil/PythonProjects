{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n0             60         65.0     8450            7            5       2003   \n1             20         80.0     9600            6            8       1976   \n2             60         68.0    11250            7            5       2001   \n3             70         60.0     9550            7            5       1915   \n4             60         84.0    14260            8            5       2000   \n...          ...          ...      ...          ...          ...        ...   \n1455          60         62.0     7917            6            5       1999   \n1456          20         85.0    13175            6            6       1978   \n1457          70         66.0     9042            7            9       1941   \n1458          20         68.0     9717            5            6       1950   \n1459          20         75.0     9937            5            6       1965   \n\n      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  WoodDeckSF  \\\n0             2003       196.0         706           0  ...           0   \n1             1976         0.0         978           0  ...         298   \n2             2002       162.0         486           0  ...           0   \n3             1970         0.0         216           0  ...           0   \n4             2000       350.0         655           0  ...         192   \n...            ...         ...         ...         ...  ...         ...   \n1455          2000         0.0           0           0  ...           0   \n1456          1988       119.0         790         163  ...         349   \n1457          2006         0.0         275           0  ...           0   \n1458          1996         0.0          49        1029  ...         366   \n1459          1965         0.0         830         290  ...         736   \n\n      OpenPorchSF  EnclosedPorch  X3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n0              61              0           0            0         0        0   \n1               0              0           0            0         0        0   \n2              42              0           0            0         0        0   \n3              35            272           0            0         0        0   \n4              84              0           0            0         0        0   \n...           ...            ...         ...          ...       ...      ...   \n1455           40              0           0            0         0        0   \n1456            0              0           0            0         0        0   \n1457           60              0           0            0         0     2500   \n1458            0            112           0            0         0        0   \n1459           68              0           0            0         0        0   \n\n      MoSold  YrSold  HousePrice  \n0          2    2008           1  \n1          5    2007           1  \n2          9    2008           1  \n3          2    2006           0  \n4         12    2008           1  \n...      ...     ...         ...  \n1455       8    2007           0  \n1456       2    2010           1  \n1457       5    2010           1  \n1458       4    2010           0  \n1459       6    2008           0  \n\n[1460 rows x 37 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>X3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>HousePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>196.0</td>\n      <td>706</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>0.0</td>\n      <td>978</td>\n      <td>0</td>\n      <td>...</td>\n      <td>298</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>162.0</td>\n      <td>486</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>0.0</td>\n      <td>216</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>35</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>350.0</td>\n      <td>655</td>\n      <td>0</td>\n      <td>...</td>\n      <td>192</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>60</td>\n      <td>62.0</td>\n      <td>7917</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1999</td>\n      <td>2000</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>20</td>\n      <td>85.0</td>\n      <td>13175</td>\n      <td>6</td>\n      <td>6</td>\n      <td>1978</td>\n      <td>1988</td>\n      <td>119.0</td>\n      <td>790</td>\n      <td>163</td>\n      <td>...</td>\n      <td>349</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>70</td>\n      <td>66.0</td>\n      <td>9042</td>\n      <td>7</td>\n      <td>9</td>\n      <td>1941</td>\n      <td>2006</td>\n      <td>0.0</td>\n      <td>275</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2500</td>\n      <td>5</td>\n      <td>2010</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>20</td>\n      <td>68.0</td>\n      <td>9717</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1950</td>\n      <td>1996</td>\n      <td>0.0</td>\n      <td>49</td>\n      <td>1029</td>\n      <td>...</td>\n      <td>366</td>\n      <td>0</td>\n      <td>112</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>20</td>\n      <td>75.0</td>\n      <td>9937</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1965</td>\n      <td>1965</td>\n      <td>0.0</td>\n      <td>830</td>\n      <td>290</td>\n      <td>...</td>\n      <td>736</td>\n      <td>68</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1460 rows × 37 columns</p>\n</div>"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('House_Price.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "MSSubClass       0\nLotFrontage      0\nLotArea          0\nOverallQual      0\nOverallCond      0\nYearBuilt        0\nYearRemodAdd     0\nMasVnrArea       0\nBsmtFinSF1       0\nBsmtFinSF2       0\nBsmtUnfSF        0\nTotalBsmtSF      0\nX1stFlrSF        0\nX2ndFlrSF        0\nLowQualFinSF     0\nGrLivArea        0\nBsmtFullBath     0\nBsmtHalfBath     0\nFullBath         0\nHalfBath         0\nBedroomAbvGr     0\nKitchenAbvGr     0\nTotRmsAbvGrd     0\nFireplaces       0\nGarageYrBlt      0\nGarageCars       0\nGarageArea       0\nWoodDeckSF       0\nOpenPorchSF      0\nEnclosedPorch    0\nX3SsnPorch       0\nScreenPorch      0\nPoolArea         0\nMiscVal          0\nMoSold           0\nYrSold           0\nHousePrice       0\ndtype: int64"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n0             60         65.0     8450            7            5       2003   \n1             20         80.0     9600            6            8       1976   \n2             60         68.0    11250            7            5       2001   \n3             70         60.0     9550            7            5       1915   \n4             60         84.0    14260            8            5       2000   \n...          ...          ...      ...          ...          ...        ...   \n1455          60         62.0     7917            6            5       1999   \n1456          20         85.0    13175            6            6       1978   \n1457          70         66.0     9042            7            9       1941   \n1458          20         68.0     9717            5            6       1950   \n1459          20         75.0     9937            5            6       1965   \n\n      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageArea  \\\n0             2003       196.0         706           0  ...         548   \n1             1976         0.0         978           0  ...         460   \n2             2002       162.0         486           0  ...         608   \n3             1970         0.0         216           0  ...         642   \n4             2000       350.0         655           0  ...         836   \n...            ...         ...         ...         ...  ...         ...   \n1455          2000         0.0           0           0  ...         460   \n1456          1988       119.0         790         163  ...         500   \n1457          2006         0.0         275           0  ...         252   \n1458          1996         0.0          49        1029  ...         240   \n1459          1965         0.0         830         290  ...         276   \n\n      WoodDeckSF  OpenPorchSF  EnclosedPorch  X3SsnPorch  ScreenPorch  \\\n0              0           61              0           0            0   \n1            298            0              0           0            0   \n2              0           42              0           0            0   \n3              0           35            272           0            0   \n4            192           84              0           0            0   \n...          ...          ...            ...         ...          ...   \n1455           0           40              0           0            0   \n1456         349            0              0           0            0   \n1457           0           60              0           0            0   \n1458         366            0            112           0            0   \n1459         736           68              0           0            0   \n\n      PoolArea  MiscVal  MoSold  YrSold  \n0            0        0       2    2008  \n1            0        0       5    2007  \n2            0        0       9    2008  \n3            0        0       2    2006  \n4            0        0      12    2008  \n...        ...      ...     ...     ...  \n1455         0        0       8    2007  \n1456         0        0       2    2010  \n1457         0     2500       5    2010  \n1458         0        0       4    2010  \n1459         0        0       6    2008  \n\n[1460 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>GarageArea</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>X3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>196.0</td>\n      <td>706</td>\n      <td>0</td>\n      <td>...</td>\n      <td>548</td>\n      <td>0</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>0.0</td>\n      <td>978</td>\n      <td>0</td>\n      <td>...</td>\n      <td>460</td>\n      <td>298</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>162.0</td>\n      <td>486</td>\n      <td>0</td>\n      <td>...</td>\n      <td>608</td>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>0.0</td>\n      <td>216</td>\n      <td>0</td>\n      <td>...</td>\n      <td>642</td>\n      <td>0</td>\n      <td>35</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>350.0</td>\n      <td>655</td>\n      <td>0</td>\n      <td>...</td>\n      <td>836</td>\n      <td>192</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>60</td>\n      <td>62.0</td>\n      <td>7917</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1999</td>\n      <td>2000</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>460</td>\n      <td>0</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>20</td>\n      <td>85.0</td>\n      <td>13175</td>\n      <td>6</td>\n      <td>6</td>\n      <td>1978</td>\n      <td>1988</td>\n      <td>119.0</td>\n      <td>790</td>\n      <td>163</td>\n      <td>...</td>\n      <td>500</td>\n      <td>349</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>70</td>\n      <td>66.0</td>\n      <td>9042</td>\n      <td>7</td>\n      <td>9</td>\n      <td>1941</td>\n      <td>2006</td>\n      <td>0.0</td>\n      <td>275</td>\n      <td>0</td>\n      <td>...</td>\n      <td>252</td>\n      <td>0</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2500</td>\n      <td>5</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>20</td>\n      <td>68.0</td>\n      <td>9717</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1950</td>\n      <td>1996</td>\n      <td>0.0</td>\n      <td>49</td>\n      <td>1029</td>\n      <td>...</td>\n      <td>240</td>\n      <td>366</td>\n      <td>0</td>\n      <td>112</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>20</td>\n      <td>75.0</td>\n      <td>9937</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1965</td>\n      <td>1965</td>\n      <td>0.0</td>\n      <td>830</td>\n      <td>290</td>\n      <td>...</td>\n      <td>276</td>\n      <td>736</td>\n      <td>68</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n    </tr>\n  </tbody>\n</table>\n<p>1460 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop([\"HousePrice\"], axis = 1)\n",
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "0       1\n1       1\n2       1\n3       0\n4       1\n       ..\n1455    0\n1456    1\n1457    1\n1458    0\n1459    0\nName: HousePrice, Length: 1460, dtype: int64"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df[\"HousePrice\"]\n",
    "Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n64            60    75.850000     9375            7            5       1997   \n682          120    63.354762     2887            6            5       1996   \n960           20    50.000000     7207            5            7       1958   \n1384          50    60.000000     9060            6            5       1939   \n1100          30    60.000000     8400            2            5       1920   \n...          ...          ...      ...          ...          ...        ...   \n763           60    82.000000     9430            8            5       1999   \n835           20    60.000000     9600            4            7       1950   \n1216          90    68.000000     8930            6            5       1978   \n559          120    46.160000     3196            7            5       2003   \n684           60    58.000000    16770            7            5       1998   \n\n      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageArea  \\\n64            1998       573.0         739           0  ...         645   \n682           1997         0.0        1003           0  ...         431   \n960           2008         0.0         696           0  ...           0   \n1384          1950         0.0         204           0  ...         280   \n1100          1950         0.0         290           0  ...         246   \n...            ...         ...         ...         ...  ...         ...   \n763           1999       673.0        1163           0  ...         856   \n835           1995         0.0         442           0  ...         436   \n1216          1978         0.0           0           0  ...         539   \n559           2004        18.0           0           0  ...         420   \n684           1998        30.0           0           0  ...         486   \n\n      WoodDeckSF  OpenPorchSF  EnclosedPorch  X3SsnPorch  ScreenPorch  \\\n64           576           36              0           0            0   \n682          307            0              0           0            0   \n960          117            0              0           0            0   \n1384           0            0              0           0            0   \n1100           0            0              0           0            0   \n...          ...          ...            ...         ...          ...   \n763            0          128              0           0          180   \n835          290            0              0           0            0   \n1216           0            0              0           0            0   \n559          143           20              0           0            0   \n684            0           81              0           0            0   \n\n      PoolArea  MiscVal  MoSold  YrSold  \n64           0        0       2    2009  \n682          0        0      11    2008  \n960          0        0       2    2010  \n1384         0        0      10    2009  \n1100         0        0       1    2009  \n...        ...      ...     ...     ...  \n763          0        0       7    2009  \n835          0        0       2    2010  \n1216         0        0       4    2010  \n559          0        0      10    2006  \n684          0        0       6    2010  \n\n[1022 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>GarageArea</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>X3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>64</th>\n      <td>60</td>\n      <td>75.850000</td>\n      <td>9375</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1997</td>\n      <td>1998</td>\n      <td>573.0</td>\n      <td>739</td>\n      <td>0</td>\n      <td>...</td>\n      <td>645</td>\n      <td>576</td>\n      <td>36</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>682</th>\n      <td>120</td>\n      <td>63.354762</td>\n      <td>2887</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1996</td>\n      <td>1997</td>\n      <td>0.0</td>\n      <td>1003</td>\n      <td>0</td>\n      <td>...</td>\n      <td>431</td>\n      <td>307</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>960</th>\n      <td>20</td>\n      <td>50.000000</td>\n      <td>7207</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1958</td>\n      <td>2008</td>\n      <td>0.0</td>\n      <td>696</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>117</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1384</th>\n      <td>50</td>\n      <td>60.000000</td>\n      <td>9060</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1939</td>\n      <td>1950</td>\n      <td>0.0</td>\n      <td>204</td>\n      <td>0</td>\n      <td>...</td>\n      <td>280</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>1100</th>\n      <td>30</td>\n      <td>60.000000</td>\n      <td>8400</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1920</td>\n      <td>1950</td>\n      <td>0.0</td>\n      <td>290</td>\n      <td>0</td>\n      <td>...</td>\n      <td>246</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>60</td>\n      <td>82.000000</td>\n      <td>9430</td>\n      <td>8</td>\n      <td>5</td>\n      <td>1999</td>\n      <td>1999</td>\n      <td>673.0</td>\n      <td>1163</td>\n      <td>0</td>\n      <td>...</td>\n      <td>856</td>\n      <td>0</td>\n      <td>128</td>\n      <td>0</td>\n      <td>0</td>\n      <td>180</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2009</td>\n    </tr>\n    <tr>\n      <th>835</th>\n      <td>20</td>\n      <td>60.000000</td>\n      <td>9600</td>\n      <td>4</td>\n      <td>7</td>\n      <td>1950</td>\n      <td>1995</td>\n      <td>0.0</td>\n      <td>442</td>\n      <td>0</td>\n      <td>...</td>\n      <td>436</td>\n      <td>290</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>1216</th>\n      <td>90</td>\n      <td>68.000000</td>\n      <td>8930</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1978</td>\n      <td>1978</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>539</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>559</th>\n      <td>120</td>\n      <td>46.160000</td>\n      <td>3196</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2004</td>\n      <td>18.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>420</td>\n      <td>143</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>684</th>\n      <td>60</td>\n      <td>58.000000</td>\n      <td>16770</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1998</td>\n      <td>1998</td>\n      <td>30.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>486</td>\n      <td>0</td>\n      <td>81</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2010</td>\n    </tr>\n  </tbody>\n</table>\n<p>1022 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_Train,X_Test,Y_Train,Y_Test = train_test_split(X,Y,test_size=0.3,random_state=0)\n",
    "# x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)\n",
    "X_Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(criterion='entropy', n_estimators=5, random_state=0)",
      "text/html": "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=5, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, n_estimators=5, random_state=0)</pre></div></div></div></div></div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "X_Train = sc_X.fit_transform(X_Train)\n",
    "X_Test = sc_X.transform(X_Test)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 5, criterion = 'entropy', random_state = 0)\n",
    "rfc.fit(X_Train,Y_Train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "Y_Pred = rfc.predict(X_Test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[255,   9],\n       [ 37, 137]])"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_Test, Y_Pred)\n",
    "cm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8949771689497716\n",
      "0.9383561643835616\n",
      "0.7873563218390804\n",
      "0.85625\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.accuracy_score(Y_Test, Y_Pred))\n",
    "print(metrics.precision_score(Y_Test, Y_Pred))\n",
    "print(metrics.recall_score(Y_Test, Y_Pred))\n",
    "print(metrics.f1_score(Y_Test, Y_Pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestRegressor(n_estimators=5, random_state=0)",
      "text/html": "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=5, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=5, random_state=0)</pre></div></div></div></div></div>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestRegressor(n_estimators = 5, random_state = 0)\n",
    "rfc.fit(X_Train,Y_Train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.6, 0.2, 0. , 1. , 0. , 0. , 0.8, 0. , 1. , 0. , 0.6, 0.2, 1. ,\n       0. , 0. , 0. , 1. , 0. , 0. , 0.4, 0. , 0. , 0. , 0. , 0.4, 1. ,\n       0.2, 0. , 1. , 0. , 0. , 0.2, 0. , 1. , 0.6, 0. , 1. , 0. , 1. ,\n       1. , 0.8, 0. , 0.8, 1. , 1. , 0. , 0. , 0. , 0.4, 0. , 1. , 0. ,\n       0. , 0. , 1. , 0. , 0. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0.4,\n       0.6, 0. , 1. , 0. , 1. , 0. , 0. , 0. , 0.8, 0. , 1. , 0. , 0. ,\n       1. , 0. , 0. , 0. , 0. , 0. , 0.8, 1. , 0. , 0.8, 0. , 0. , 0.8,\n       0.8, 0.4, 1. , 0.4, 0. , 1. , 0.4, 0. , 0.4, 0.8, 0.4, 0. , 0. ,\n       0. , 0.8, 0. , 0. , 0.2, 0. , 0. , 0. , 0.4, 0. , 0.2, 0.2, 0.6,\n       0. , 0.6, 1. , 0.4, 0.2, 0. , 1. , 0.8, 0.8, 1. , 0.6, 1. , 0. ,\n       0.8, 0.6, 0.2, 0. , 0. , 1. , 0. , 0.4, 0. , 0.4, 0. , 0. , 0.8,\n       0. , 0. , 0.2, 1. , 0. , 1. , 1. , 0. , 1. , 1. , 0.6, 0. , 0.8,\n       0. , 0.6, 0.2, 0. , 0. , 0. , 0.4, 0. , 1. , 0. , 0. , 1. , 1. ,\n       0.2, 0. , 0. , 0.4, 0. , 0. , 0. , 0. , 0.8, 0. , 0. , 1. , 1. ,\n       0. , 1. , 0. , 0.4, 0. , 1. , 0.6, 0. , 0.2, 0. , 1. , 0. , 0. ,\n       0. , 0. , 0. , 0.4, 0. , 0. , 0.4, 0. , 0. , 0.2, 0.2, 0. , 1. ,\n       1. , 0. , 0.2, 1. , 0. , 0. , 1. , 0.6, 0.4, 1. , 1. , 0. , 0.6,\n       0.2, 0.4, 0. , 0.4, 1. , 1. , 1. , 0. , 0.4, 0. , 0.2, 0. , 0. ,\n       1. , 0. , 0. , 0. , 0. , 0.4, 0. , 0.6, 1. , 1. , 0. , 0.6, 0.8,\n       0.4, 0. , 0.8, 0. , 1. , 0. , 1. , 1. , 1. , 0. , 0.6, 1. , 1. ,\n       0.2, 0.2, 0. , 0. , 1. , 1. , 1. , 0. , 0.8, 1. , 0. , 0.8, 0. ,\n       0.4, 0.2, 1. , 1. , 0.8, 1. , 0. , 0. , 1. , 0. , 0. , 0.6, 0.2,\n       0. , 1. , 1. , 0.4, 0. , 0. , 0.8, 0. , 0. , 1. , 1. , 0.8, 0. ,\n       0. , 0. , 0. , 0.2, 0. , 0.4, 0. , 0. , 0. , 0. , 0.2, 0. , 0.6,\n       0.4, 0. , 0. , 0. , 1. , 0. , 0. , 0. , 0. , 1. , 0. , 1. , 0. ,\n       1. , 0. , 1. , 0.6, 0.2, 0. , 0.8, 0.2, 0.6, 0.2, 0. , 0. , 0.2,\n       0.2, 0. , 1. , 0.2, 0.2, 1. , 0. , 0. , 0. , 0. , 0. , 0. , 1. ,\n       1. , 0. , 0. , 0.2, 1. , 1. , 0. , 1. , 1. , 1. , 0.6, 1. , 1. ,\n       0. , 0. , 0. , 0. , 0.4, 0. , 0.6, 0. , 0. , 0. , 0. , 0.2, 0.6,\n       1. , 0. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. , 1. ,\n       0. , 0. , 1. , 0. , 0. , 0. , 0.2, 0.2, 0. , 0.6, 1. , 1. , 0.2,\n       0. , 0. , 1. , 0. , 1. , 1. , 1. , 0. , 0. , 1. , 0. , 0. , 0. ,\n       1. , 0. , 1. , 0. , 1. , 1. , 0. , 0. , 0. , 0. , 0.4, 0. , 0.2,\n       0. , 0. , 1. , 0. , 0.8, 0. , 1. , 1. , 1. ])"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Pred = rfc.predict(X_Test)\n",
    "Y_Pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13287671232876713\n",
      "0.08063926940639271\n",
      "0.6632236154649946\n"
     ]
    }
   ],
   "source": [
    "print(metrics.mean_absolute_error(Y_Test, Y_Pred))\n",
    "print(metrics.mean_squared_error(Y_Test, Y_Pred))\n",
    "\n",
    "# 50-den assa jaksy!!!\n",
    "print(metrics.r2_score(Y_Test, Y_Pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "GradientBoostingClassifier(n_estimators=5, random_state=0)",
      "text/html": "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(n_estimators=5, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(n_estimators=5, random_state=0)</pre></div></div></div></div></div>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=5, random_state=0)\n",
    "gbc.fit(X_Train, Y_Train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n       1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n       1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1])"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Pred = gbc.predict(X_Test)\n",
    "Y_Pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[250,  14],\n       [ 51, 123]])"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_Test, Y_Pred)\n",
    "cm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8515981735159818\n",
      "0.8978102189781022\n",
      "0.7068965517241379\n",
      "0.7909967845659164\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Y_Test, Y_Pred))\n",
    "print(metrics.precision_score(Y_Test, Y_Pred))\n",
    "print(metrics.recall_score(Y_Test, Y_Pred))\n",
    "print(metrics.f1_score(Y_Test, Y_Pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "GradientBoostingRegressor(n_estimators=5, random_state=0)",
      "text/html": "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(n_estimators=5, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(n_estimators=5, random_state=0)</pre></div></div></div></div></div>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingRegressor(n_estimators=5, random_state=0)\n",
    "gbc.fit(X_Train, Y_Train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.4274498 , 0.29260572, 0.23126599, 0.56815801, 0.23126599,\n       0.23126599, 0.60644543, 0.23126599, 0.60644543, 0.25340702,\n       0.58939822, 0.44455023, 0.60644543, 0.23126599, 0.23126599,\n       0.23126599, 0.55777826, 0.23126599, 0.23126599, 0.49980415,\n       0.23126599, 0.23126599, 0.23126599, 0.23126599, 0.31687852,\n       0.55023181, 0.44012144, 0.23126599, 0.60644543, 0.23126599,\n       0.36563145, 0.40909055, 0.23126599, 0.60644543, 0.60644543,\n       0.25340702, 0.60644543, 0.23126599, 0.60644543, 0.60644543,\n       0.38238233, 0.23126599, 0.5111993 , 0.60644543, 0.60644543,\n       0.36563145, 0.23126599, 0.23126599, 0.3715245 , 0.23126599,\n       0.60644543, 0.23126599, 0.23126599, 0.23126599, 0.60644543,\n       0.23126599, 0.23126599, 0.60644543, 0.23126599, 0.23126599,\n       0.23126599, 0.23126599, 0.23126599, 0.23126599, 0.40942839,\n       0.3402831 , 0.23126599, 0.60644543, 0.23126599, 0.55023181,\n       0.36992414, 0.23126599, 0.23126599, 0.5771146 , 0.23126599,\n       0.60644543, 0.23126599, 0.23126599, 0.60644543, 0.23126599,\n       0.23126599, 0.23126599, 0.23126599, 0.23126599, 0.41307539,\n       0.49891568, 0.23126599, 0.58939822, 0.23126599, 0.23126599,\n       0.47802532, 0.42900375, 0.29986293, 0.60644543, 0.49891568,\n       0.23126599, 0.60644543, 0.29260572, 0.23126599, 0.29260572,\n       0.60644543, 0.30962064, 0.23126599, 0.23126599, 0.23126599,\n       0.58939822, 0.23126599, 0.23126599, 0.23126599, 0.23126599,\n       0.23126599, 0.23126599, 0.36405381, 0.23126599, 0.30962064,\n       0.23126599, 0.60644543, 0.23126599, 0.36405381, 0.60644543,\n       0.46077164, 0.28028981, 0.23126599, 0.56815801, 0.58939822,\n       0.60644543, 0.60644543, 0.49891568, 0.49891568, 0.23126599,\n       0.5771146 , 0.49891568, 0.3957973 , 0.25922424, 0.23126599,\n       0.60644543, 0.23126599, 0.5771146 , 0.23126599, 0.44012144,\n       0.23126599, 0.23126599, 0.38954592, 0.23126599, 0.23126599,\n       0.29986293, 0.60644543, 0.23126599, 0.60644543, 0.60644543,\n       0.23126599, 0.60644543, 0.60644543, 0.40380397, 0.25340702,\n       0.56815801, 0.23126599, 0.51194439, 0.23126599, 0.36992414,\n       0.23126599, 0.23126599, 0.30962064, 0.23126599, 0.60644543,\n       0.23126599, 0.23126599, 0.60644543, 0.5771146 , 0.3715245 ,\n       0.23126599, 0.3715245 , 0.23126599, 0.23126599, 0.23126599,\n       0.23126599, 0.23126599, 0.45097927, 0.23126599, 0.23126599,\n       0.60644543, 0.55777826, 0.23126599, 0.60644543, 0.23126599,\n       0.29260572, 0.23126599, 0.49891568, 0.5771146 , 0.23126599,\n       0.23126599, 0.23126599, 0.60644543, 0.23126599, 0.23126599,\n       0.23126599, 0.23126599, 0.23126599, 0.31218108, 0.23126599,\n       0.23126599, 0.5111993 , 0.23126599, 0.23126599, 0.36590009,\n       0.40195769, 0.23126599, 0.60644543, 0.60644543, 0.23126599,\n       0.23126599, 0.60644543, 0.23126599, 0.23126599, 0.60644543,\n       0.36405381, 0.53882719, 0.60644543, 0.60644543, 0.23126599,\n       0.60644543, 0.23126599, 0.29260572, 0.23126599, 0.58939822,\n       0.60644543, 0.60644543, 0.38954592, 0.23126599, 0.55111081,\n       0.23126599, 0.28028981, 0.23126599, 0.23126599, 0.55023181,\n       0.23126599, 0.31687852, 0.23126599, 0.23126599, 0.3402831 ,\n       0.23126599, 0.44012144, 0.55023181, 0.60644543, 0.23126599,\n       0.5111993 , 0.5771146 , 0.30962064, 0.23126599, 0.5771146 ,\n       0.23126599, 0.60644543, 0.23126599, 0.60644543, 0.49891568,\n       0.60644543, 0.23126599, 0.60644543, 0.60644543, 0.60644543,\n       0.55023181, 0.23126599, 0.34447845, 0.23126599, 0.60644543,\n       0.58939822, 0.60644543, 0.23126599, 0.53897057, 0.60644543,\n       0.23126599, 0.53897057, 0.23126599, 0.3715245 , 0.31687852,\n       0.60644543, 0.55777826, 0.49980415, 0.55023181, 0.23126599,\n       0.23126599, 0.60644543, 0.23126599, 0.23126599, 0.49891568,\n       0.4274498 , 0.23126599, 0.58939822, 0.60644543, 0.31687852,\n       0.23126599, 0.23126599, 0.60644543, 0.23126599, 0.23126599,\n       0.60644543, 0.60644543, 0.5111993 , 0.23126599, 0.28028981,\n       0.23126599, 0.23126599, 0.25340702, 0.23126599, 0.31687852,\n       0.23126599, 0.23126599, 0.23126599, 0.25340702, 0.49891568,\n       0.23126599, 0.23126599, 0.55111081, 0.23126599, 0.23126599,\n       0.23126599, 0.60644543, 0.23126599, 0.58939822, 0.36405381,\n       0.23126599, 0.60644543, 0.23126599, 0.56815801, 0.36590009,\n       0.60644543, 0.23126599, 0.60644543, 0.3305096 , 0.23126599,\n       0.23126599, 0.54073106, 0.29260572, 0.5111993 , 0.34939592,\n       0.23126599, 0.23126599, 0.28028981, 0.25340702, 0.23126599,\n       0.60644543, 0.23126599, 0.30962064, 0.55023181, 0.23126599,\n       0.23126599, 0.23126599, 0.23126599, 0.23126599, 0.23126599,\n       0.60644543, 0.60644543, 0.23126599, 0.23126599, 0.23126599,\n       0.60644543, 0.60644543, 0.35008497, 0.60644543, 0.38238233,\n       0.60644543, 0.42339723, 0.60644543, 0.60644543, 0.23126599,\n       0.31687852, 0.36992414, 0.23126599, 0.49199417, 0.23126599,\n       0.60644543, 0.23126599, 0.31687852, 0.23126599, 0.23126599,\n       0.23126599, 0.3402831 , 0.60644543, 0.23126599, 0.60644543,\n       0.23126599, 0.23126599, 0.23126599, 0.23126599, 0.23126599,\n       0.23126599, 0.23126599, 0.30962064, 0.60644543, 0.60644543,\n       0.23126599, 0.23126599, 0.38238233, 0.23126599, 0.23126599,\n       0.23126599, 0.49891568, 0.23126599, 0.23126599, 0.40942839,\n       0.60644543, 0.60644543, 0.29260572, 0.23126599, 0.23126599,\n       0.60644543, 0.23126599, 0.60644543, 0.60644543, 0.60644543,\n       0.3715245 , 0.23126599, 0.58939822, 0.31687852, 0.29260572,\n       0.23126599, 0.58939822, 0.23126599, 0.60644543, 0.23126599,\n       0.60644543, 0.60644543, 0.23126599, 0.23126599, 0.23126599,\n       0.23126599, 0.56815801, 0.23126599, 0.54073106, 0.23126599,\n       0.23126599, 0.60644543, 0.23126599, 0.58939822, 0.32056398,\n       0.60644543, 0.60644543, 0.60644543])"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Pred = gbc.predict(X_Test)\n",
    "Y_Pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3516443774291465\n",
      "0.14329941991939324\n",
      "0.401534005681468\n"
     ]
    }
   ],
   "source": [
    "print(metrics.mean_absolute_error(Y_Test, Y_Pred))\n",
    "print(metrics.mean_squared_error(Y_Test, Y_Pred))\n",
    "\n",
    "# 50-den assa jaksy!!!\n",
    "print(metrics.r2_score(Y_Test, Y_Pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(X_Train, Y_Train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_Pred = xgb.predict(X_Test)\n",
    "Y_Pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(metrics.mean_absolute_error(Y_Test, Y_Pred))\n",
    "print(metrics.mean_squared_error(Y_Test, Y_Pred))\n",
    "\n",
    "# 50-den assa jaksy!!!\n",
    "print(metrics.r2_score(Y_Test, Y_Pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_Train, Y_Train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_Pred = xgb.predict(X_Test)\n",
    "Y_Pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(Y_Test, Y_Pred))\n",
    "print(metrics.precision_score(Y_Test, Y_Pred))\n",
    "print(metrics.recall_score(Y_Test, Y_Pred))\n",
    "print(metrics.f1_score(Y_Test, Y_Pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
